{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-512ba712fc0fc065",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "JvJJrUojcJ0L"
      },
      "source": [
        "## Home assignment 08: Feature importances\n",
        "\n",
        "\n",
        "Please, fill the lines in the code below.\n",
        "Your goal is to estimate importance of the existing features using several methods.\n",
        "\n",
        "Your main goal is to estimate feature importances for Logistic Regression and Gradient Boosting using several methods.\n",
        "\n",
        "The model should be trained using only `train` part of the data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-b656a4266174b009",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "O9lVPfkbcJ0P"
      },
      "source": [
        "In this task you meet the [dataset](https://archive.ics.uci.edu/ml/datasets/Statlog+%28Vehicle+Silhouettes%29) describing different cars for multiclass ($k=4$) classification problem, but we use only binary subset for classes `bus` and `opel`. The data is available below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UEM6RYnEcJ0P",
        "outputId": "e8ba554b-55e1-4743-b8c3-a6cdbc978b25",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting shap\n",
            "  Downloading shap-0.43.0-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (532 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m532.9/532.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from shap) (1.23.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from shap) (1.11.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from shap) (1.2.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from shap) (1.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27.0 in /usr/local/lib/python3.10/dist-packages (from shap) (4.66.1)\n",
            "Requirement already satisfied: packaging>20.9 in /usr/local/lib/python3.10/dist-packages (from shap) (23.2)\n",
            "Collecting slicer==0.0.7 (from shap)\n",
            "  Downloading slicer-0.0.7-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from shap) (0.58.1)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from shap) (2.2.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->shap) (0.41.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->shap) (2023.3.post1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->shap) (3.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->shap) (1.16.0)\n",
            "Installing collected packages: slicer, shap\n",
            "Successfully installed shap-0.43.0 slicer-0.0.7\n",
            "--2023-11-26 11:47:15--  https://raw.githubusercontent.com/girafe-ai/ml-course/23f_basic/homeworks/lab01_ml_pipeline/car_data.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 58374 (57K) [text/plain]\n",
            "Saving to: ‘car_data.csv’\n",
            "\n",
            "car_data.csv        100%[===================>]  57.01K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-11-26 11:47:16 (3.70 MB/s) - ‘car_data.csv’ saved [58374/58374]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# If on colab, uncomment the following lines\n",
        "! pip install shap\n",
        "! wget https://raw.githubusercontent.com/girafe-ai/ml-course/23f_basic/homeworks/lab01_ml_pipeline/car_data.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-eebac6bfdf73d0bc",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "EykLaY5vcJ0R",
        "outputId": "f4701af6-f955-4ef3-b4c0-622f9a7299ce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(430, 19) (430,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import shap\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "\n",
        "dataset = pd.read_csv('car_data.csv', delimiter=',', header=None).values\n",
        "data = dataset[:, :-1].astype(int)\n",
        "target = dataset[:, -1]\n",
        "binary_subset = np.array([x in ['bus', 'opel'] for x in target])\n",
        "data, target = data[binary_subset], target[binary_subset]\n",
        "\n",
        "print(data.shape, target.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "em_CAsbfcJ0S"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "submission_dict = {}\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3bNZ7h9FcJ0S",
        "outputId": "327b80e3-338a-4410-fc10-2a4ffd250631",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(350, 18) (350,) (80, 18) (80,)\n"
          ]
        }
      ],
      "source": [
        "X_train, y_train = data[:350, 1:], target[:350]\n",
        "X_val, y_val = data[350:, 1:], target[350:]\n",
        "print(X_train.shape, y_train.shape, X_val.shape, y_val.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nbgrader": {
          "grade": false,
          "grade_id": "cell-be844269be69c387",
          "locked": true,
          "schema_version": 2,
          "solution": false
        },
        "id": "mQjD1gx5cJ0T"
      },
      "source": [
        "#### Estimating features importances using logistic regression coefficients.\n",
        "Train basic logistic regression and save its coefficients (weights)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bykrNuJKcJ0T",
        "outputId": "3886fee0-9117-413d-bcf8-96acf192b123",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 75
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(solver='newton-cg')"
            ],
            "text/html": [
              "<style>#sk-container-id-11 {color: black;background-color: white;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "lr_basic = LogisticRegression(max_iter = 100, solver = 'newton-cg')# YOUR CODE HERE\n",
        "lr_basic.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeR2IwpbcJ0U"
      },
      "source": [
        "Check the classification results on the original train data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "obyEcBR0cJ0U",
        "outputId": "d89d04dc-d6fd-4858-c2a4-7d645f026d4a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bus       0.99      0.99      0.99       175\n",
            "        opel       0.99      0.99      0.99       175\n",
            "\n",
            "    accuracy                           0.99       350\n",
            "   macro avg       0.99      0.99      0.99       350\n",
            "weighted avg       0.99      0.99      0.99       350\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_train, lr_basic.predict(X_train)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "leLBM6d-cJ0U"
      },
      "source": [
        "And on validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "rcnkq47QcJ0U",
        "outputId": "85aec070-6493-406d-f513-66fc703cb4aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bus       1.00      0.98      0.99        43\n",
            "        opel       0.97      1.00      0.99        37\n",
            "\n",
            "    accuracy                           0.99        80\n",
            "   macro avg       0.99      0.99      0.99        80\n",
            "weighted avg       0.99      0.99      0.99        80\n",
            "\n"
          ]
        }
      ],
      "source": [
        "print(classification_report(y_val, lr_basic.predict(X_val)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UenvvVhIcJ0V"
      },
      "source": [
        "Find the Logistic Regression weights and save them to the variable `lr_basic_coef`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "vAUl2vHDcJ0V",
        "outputId": "d09d5244-0f5b-4d1c-812c-90f7b33757a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-0.11187858  0.21607778  0.19126796  0.77337714 -2.35220694  0.09870487\n",
            "   0.04881377  0.87078055 -0.02142932 -0.02301263 -0.336603   -0.0044345\n",
            "  -0.07796589  0.0593064   0.26825855 -0.11143085 -1.59570219  0.9431357 ]]\n"
          ]
        }
      ],
      "source": [
        "lr_basic_coef = lr_basic.coef_\n",
        "print(lr_basic_coef) # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "neUWx0rCcJ0V"
      },
      "source": [
        "It should have the same number of coefficients as number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "bqNEhSdqcJ0V"
      },
      "outputs": [],
      "source": [
        "assert lr_basic_coef.shape[-1] == X_train.shape[1]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "WEjKQcvCcJ0V"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "submission_dict['lr_basic_coef'] = lr_basic_coef\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Luqvp4SDcJ0V"
      },
      "source": [
        "#### Estimating features importances using logistic regression coefficients.\n",
        "Train basic logistic regression on scaled data and save its coefficients (weights) as well"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dwe7OUbBcJ0W"
      },
      "outputs": [],
      "source": [
        "lr_scaled = lr_basic. # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yn_Ur9SicJ0W"
      },
      "source": [
        "Use `StandardScaler` on your data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJM6RDYzcJ0W"
      },
      "outputs": [],
      "source": [
        "scaler = # YOUR CODE HERE\n",
        "X_train_scaled = # YOUR CODE HERE\n",
        "X_val_scaled = # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqgtD9QLcJ0W"
      },
      "outputs": [],
      "source": [
        "# YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRfP7FuEcJ0W"
      },
      "source": [
        "Check the classification results on the scaled train data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SVgSdBtMcJ0W"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_train, lr_scaled.predict(X_train_scaled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_1_E5R_ycJ0W"
      },
      "source": [
        "And on validation:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gbqWutJwcJ0W"
      },
      "outputs": [],
      "source": [
        "print(classification_report(y_val, lr_scaled.predict(X_val_scaled)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FaMqi1r2cJ0X"
      },
      "source": [
        "Save model coefficients to the variable `lr_scaled_coef`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R6FjOnlbcJ0X"
      },
      "outputs": [],
      "source": [
        "lr_scaled_coef = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHbp4NyHcJ0X"
      },
      "source": [
        "It should also have the same number of coefficients as number of features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2xZ7Xd6ScJ0X"
      },
      "outputs": [],
      "source": [
        "assert lr_scaled_coef.shape[-1] == X_train_scaled.shape[1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50WtT2oKcJ0X"
      },
      "source": [
        "Save index of the most important feature for lr_scaled to the variable `lr_scaled_most_important_index`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bqryoQgAcJ0X"
      },
      "outputs": [],
      "source": [
        "lr_scaled_most_important_index = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D6cagkIwcJ0X"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert isinstance(int(lr_scaled_most_important_index), int)\n",
        "submission_dict['lr_scaled_coef'] = lr_scaled_coef\n",
        "submission_dict['lr_scaled_most_important_index'] = lr_scaled_most_important_index\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpjfZCLEcJ0Y"
      },
      "source": [
        "#### Estimating features importances for logistic regression using shap\n",
        "Use [`shap` library](https://shap.readthedocs.io/en/latest/index.html) to check the importance of the features. Use [`Linear` explainer](https://shap.readthedocs.io/en/latest/generated/shap.explainers.Linear.html) and the scaled data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_4zLdRbcJ0Y"
      },
      "outputs": [],
      "source": [
        "explainer = None # YOUR CODE HERE\n",
        "shap_values_scaled = explainer(X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwANzkQ_cJ0Y"
      },
      "source": [
        "Summary plot:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ve_fRwWPcJ0Y"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values_scaled, X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XG3Eqt0xcJ0Y"
      },
      "source": [
        "Finally, write a function which transforms shap values to Logistic Regression coefficients. Their relations are described in the [docs](https://shap.readthedocs.io/en/latest/generated/shap.explainers.Linear.html).\n",
        "\n",
        "*Note: This task main goal is your deeper understanding of the shap importance estimation process.*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjvFhm6CcJ0Y"
      },
      "outputs": [],
      "source": [
        "def get_coef_from_shap_values(shap_values, X_train_scaled):\n",
        "    # YOUR CODE HERE\n",
        "    return None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6tEEtO1acJ0e"
      },
      "outputs": [],
      "source": [
        "coef_from_shap = get_coef_from_shap_values(shap_values_scaled, X_train_scaled)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kRbQriucJ0e"
      },
      "source": [
        "If everything is correct, the next assert should pass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Teiw7NoTcJ0e"
      },
      "outputs": [],
      "source": [
        "assert np.allclose(coef_from_shap, lr_scaled_coef)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zt1sNOD_cJ0e"
      },
      "source": [
        "#### Training the GradientBoosting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9g0D8mmTcJ0e"
      },
      "outputs": [],
      "source": [
        "gb_basic = GradientBoostingClassifier(n_estimators=10)\n",
        "gb_basic.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lCSD3llzcJ0e"
      },
      "outputs": [],
      "source": [
        "gb_basic_feature_importances = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M72z9hEMcJ0f"
      },
      "outputs": [],
      "source": [
        "gb_scaled = GradientBoostingClassifier(n_estimators=10)\n",
        "gb_scaled.fit(X_train_scaled, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLvTtrOFcJ0f"
      },
      "outputs": [],
      "source": [
        "gb_scaled_feature_importances = None # YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tJ3a8LmjcJ0f"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert np.allclose(gb_basic_feature_importances, gb_scaled_feature_importances, atol=1e-1)\n",
        "submission_dict['gb_basic_feature_importances'] = gb_basic_feature_importances\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qWeK_pk4cJ0f"
      },
      "source": [
        "**Question:** Why are the feature importances so similar for scaled and unscaled data?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JC19sTK9cJ0f"
      },
      "source": [
        "#### Using shap to explain trees ensemble solution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Za9rfPmcJ0f"
      },
      "outputs": [],
      "source": [
        "explainer = None # YOUR CODE HERE\n",
        "shap_values = explainer.shap_values(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LtMxfwE-cJ0g"
      },
      "outputs": [],
      "source": [
        "shap.summary_plot(shap_values, X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FeT2mg0CcJ0g"
      },
      "outputs": [],
      "source": [
        "gb_scaled_most_important_index = None # YOUR ANSWER HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ANV_oFK_cJ0g"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "assert isinstance(int(gb_scaled_most_important_index), int)\n",
        "submission_dict['gb_scaled_most_important_index'] = gb_scaled_most_important_index\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YBwfbAyDcJ0g"
      },
      "outputs": [],
      "source": [
        "# do not change the code in the block below\n",
        "# __________start of block__________\n",
        "np.save('submission_dict_hw08.npy', submission_dict, allow_pickle=True)\n",
        "print('File saved to `submission_dict_hw.npy`')\n",
        "# __________end of block__________"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wRsiA7ibcJ0g"
      },
      "source": [
        "Great job! Please, submit your solution to the grading system! Please, note, you need to submit both `submission_dict_hw.npy` and `get_coef_from_shap_values` function code."
      ]
    }
  ],
  "metadata": {
    "celltoolbar": "Create Assignment",
    "kernelspec": {
      "display_name": "Py3 Research",
      "language": "python",
      "name": "py3_research"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}